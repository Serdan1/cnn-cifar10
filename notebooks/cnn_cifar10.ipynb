{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec01811",
   "metadata": {},
   "source": [
    "\n",
    "# üß† Clasificaci√≥n de Im√°genes con CNN ‚Äî CIFAR-10 (Colab)\n",
    "**Autores:** Daniel Serrano y Alexander Arrosquipa  \n",
    "**Universidad UNIE ‚Äî Asignatura:** Lenguaje Natural y Compiladores  \n",
    "**Fecha:** Octubre 2025\n",
    "\n",
    "> Notebook listo para ejecutar en **Google Colab**. Contiene las fases 1‚Äì3: preparaci√≥n del dataset, construcci√≥n del modelo CNN, entrenamiento, evaluaci√≥n y visualizaci√≥n de resultados, adem√°s de la **Pregunta de An√°lisis**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773baad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üîß Instalaci√≥n (Colab)\n",
    "# Esta celda asegura que las dependencias est√©n disponibles en Colab.\n",
    "# (En Colab normalmente ya hay TensorFlow, pero lo dejamos por compatibilidad)\n",
    "!pip -q install tensorflow matplotlib numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üì¶ Importaciones\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Hacer que las figuras se vean bien en Colab\n",
    "plt.rcParams['figure.figsize'] = (6,6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14517976",
   "metadata": {},
   "source": [
    "\n",
    "## ‚öôÔ∏è Fase 1 ‚Äî Preparaci√≥n del Dataset (CIFAR-10)\n",
    "\n",
    "- **Carga** del dataset (`tensorflow.keras.datasets.cifar10`).\n",
    "- **Normalizaci√≥n** de p√≠xeles al rango \\([0,1]\\).\n",
    "- **One-hot encoding** de etiquetas.\n",
    "- **Visualizaci√≥n** de 9 im√°genes con su clase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8588fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üì• Carga del dataset y preprocesamiento\n",
    "# Carga\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalizaci√≥n al rango [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32')  / 255.0\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test, 10)\n",
    "\n",
    "# Resumen\n",
    "print(\"Tama√±o entrenamiento:\", x_train.shape, \"| Tama√±o prueba:\", x_test.shape)\n",
    "print(\"Ejemplo etiqueta one-hot:\", y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18784d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üñºÔ∏è Visualizaci√≥n de CIFAR-10 (9 ejemplos)\n",
    "class_names = ['avi√≥n', 'autom√≥vil', 'p√°jaro', 'gato', 'ciervo',\n",
    "               'perro', 'rana', 'caballo', 'barco', 'cami√≥n']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(6,6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(x_train[i])\n",
    "    ax.set_title(class_names[np.argmax(y_train[i])])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2656d",
   "metadata": {},
   "source": [
    "\n",
    "## üß† Fase 2 ‚Äî Construcci√≥n del Modelo (CNN)\n",
    "\n",
    "Arquitectura **Sequential** con dos bloques convolucionales (Conv2D + MaxPooling) y clasificador denso:\n",
    "- `Conv2D(32, 3√ó3, ReLU)` ‚Üí `MaxPooling(2√ó2)`  \n",
    "- `Conv2D(64, 3√ó3, ReLU)` ‚Üí `MaxPooling(2√ó2)`  \n",
    "- `Flatten` ‚Üí `Dense(64, ReLU)` ‚Üí `Dense(10, Softmax)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b62f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üß© Definici√≥n de la CNN\n",
    "model = Sequential(name=\"CNN_CIFAR10_Base\")\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3), name=\"Conv2D_1\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), name=\"MaxPool_1\"))\n",
    "model.add(Conv2D(64, (3,3), activation='relu', name=\"Conv2D_2\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), name=\"MaxPool_2\"))\n",
    "model.add(Flatten(name=\"Flatten\"))\n",
    "model.add(Dense(64, activation='relu', name=\"Dense_64\"))\n",
    "model.add(Dense(10, activation='softmax', name=\"Output\"))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858106e2",
   "metadata": {},
   "source": [
    "\n",
    "## üìà Fase 3 ‚Äî Entrenamiento y Evaluaci√≥n\n",
    "\n",
    "- **Compilaci√≥n:** `optimizer=Adam`, `loss=categorical_crossentropy`, `metrics=['accuracy']`  \n",
    "- **Entrenamiento:** 8 √©pocas, `batch_size=64`, `validation_split=0.1`  \n",
    "- **Evaluaci√≥n:** precisi√≥n y p√©rdida en el conjunto de **test**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üèãÔ∏è Compilaci√≥n y entrenamiento (8 √©pocas)\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=8,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Entrenamiento completado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab223cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üß™ Evaluaci√≥n en test\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f\"üìä Resultado en test ‚Üí Loss: {test_loss:.4f} | Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üìä Gr√°ficas de precisi√≥n y p√©rdida\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Precisi√≥n\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, acc, 'o-', label='Entrenamiento')\n",
    "plt.plot(epochs, val_acc, 'o-', label='Validaci√≥n')\n",
    "plt.title('Precisi√≥n')\n",
    "plt.xlabel('√âpocas'); plt.ylabel('Accuracy'); plt.legend()\n",
    "\n",
    "# P√©rdida\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, loss, 'o-', label='Entrenamiento')\n",
    "plt.plot(epochs, val_loss, 'o-', label='Validaci√≥n')\n",
    "plt.title('P√©rdida')\n",
    "plt.xlabel('√âpocas'); plt.ylabel('Loss'); plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fda5d3",
   "metadata": {},
   "source": [
    "\n",
    "## üí¨ Pregunta de An√°lisis\n",
    "\n",
    "**¬øQu√© partes del modelo corresponden a (1) *Input*, (2) *Preprocessing*, (3) *Feature Extraction* y (4) *Classifier*?  \n",
    "¬øC√≥mo ha automatizado la CNN el proceso de *Feature Extraction*?**\n",
    "\n",
    "**Respuesta (resumen t√©cnico):**  \n",
    "1) **Input**: los tensores de im√°genes `x_train/x_test` con forma `(32,32,3)`.  \n",
    "2) **Preprocessing**: la **normalizaci√≥n** de p√≠xeles a \\([0,1]\\) y el **one-hot encoding** de etiquetas.  \n",
    "3) **Feature Extraction**: las capas **Conv2D** y **MaxPooling2D**, que aprenden jer√°rquicamente filtros (bordes, texturas, formas) y reducen la dimensionalidad manteniendo informaci√≥n relevante.  \n",
    "4) **Classifier**: `Flatten ‚Üí Dense(64, ReLU) ‚Üí Dense(10, Softmax)` que combinan las caracter√≠sticas extra√≠das y producen probabilidades por clase.  \n",
    "\n",
    "La **CNN automatiza la extracci√≥n de caracter√≠sticas** porque los filtros de `Conv2D` **no est√°n predefinidos**: se **aprenden** mediante **retropropagaci√≥n del gradiente** para minimizar la **entrop√≠a cruzada**. As√≠, el modelo descubre representaciones discriminativas sin ingenier√≠a manual de rasgos.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
